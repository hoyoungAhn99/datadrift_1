seed: 42

data:
  json_path: "C:/Users/DMLab/Desktop/step0/labels"
  image_path: "C:/Users/DMLab/Desktop/step0/images"
  num_workers: 4
  flip_p: 0.5

training:
  pretrained: True
  model_name: "openai/clip-vit-base-patch32"
  exemplar_k: 50
  knn: 1
  batch_size: 512
  epochs: 200
  save_path: "best.pt"
  loss: "MS"
  min_lr: 0.000002
  max_lr: 0.0002
  weight_decay: 0.0001

logging:
  log_dir: "./lightning_logs"
  exp_name: "vericar_experiment"

step1:
  json_path: "F:/dataset_final/step1/labels"
  image_path: "F:/dataset_final/step1/images"
  ckpt_path: "C:/Users/DMLab/GITHUB/vericar/best-model-epoch=86-val_prec1=0.87.ckpt"
  ood_k: 1

step2:
  json_path: "F:/dataset_final/step2/labels"
  image_path: "F:/dataset_final/step2/images"
  ckpt_path: "C:/Users/DMLab/GITHUB/vericar/checkpoints_step1/step1_updated_model.ckpt"
  ood_k: 1

step3:
  json_path: "F:/dataset_final/step3/labels"
  image_path: "F:/dataset_final/step3/images"
  ckpt_path: "C:/Users/DMLab/GITHUB/vericar/checkpoints_step2/step2_updated_model.ckpt"
  ood_k: 1